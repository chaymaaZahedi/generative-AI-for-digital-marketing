
import asyncio
import json
import logging
import os
import csv
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, asdict
from urllib.parse import quote
from datetime import datetime

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

import anthropic

from app.config import settings
from app.services.db_service import db_service
from app.services.log_service import LogCollector

# Configure logging
logger = logging.getLogger(__name__)



# ============================================================================
# Helper Functions
# ============================================================================

def load_location_ids_from_csv(csv_path: str) -> Dict[str, str]:
    mapping = {}
    try:
        with open(csv_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                name = row["name"].strip().lower()
                loc_id = row["location_id"].strip()
                mapping[name] = loc_id
                mapping[name] = loc_id
        LogCollector.add(f"ðŸ“ Loaded {len(mapping)} locations from CSV.")
    except Exception as e:
        LogCollector.add(f"âŒ Failed to load CSV file {csv_path}: {e}")
    return mapping

# Load locations once
LOCATION_IDS = load_location_ids_from_csv(settings.LOCATION_CSV_PATH)

def build_linkedin_search_url(keywords: str, location_id: str) -> str:
    encoded_keywords = quote(keywords)
    return (
        f"https://www.linkedin.com/search/results/people/"
        f"?keywords={encoded_keywords}"
        f"&geoUrn=%5B%22{location_id}%22%5D"
        f"&origin=FACETED_SEARCH"
    )

# ============================================================================
# Data Model
# ============================================================================

@dataclass
class ProfileData:
    """Structured profile data"""
    name: Optional[str] = None
    url: Optional[str] = None
    location: Optional[str] = None
    keyword: Optional[str] = None
    position: Optional[str] = None
    gender: Optional[str] = None
    image_url: Optional[str] = None
    search_rank: int = 0
    education: Optional[List[Dict[str, Any]]] = None
    estimated_age: Optional[int] = None

    def is_complete(self) -> bool:
        return all([self.name, self.url, self.location, self.gender])

    def to_dict(self) -> dict:
        return asdict(self)

# ============================================================================
# LinkedIn Autonomous Agent
# ============================================================================

class LinkedInAutonomousAgent:
    """Autonomous AI Agent for LinkedIn Profile Extraction"""

    def __init__(self, linkedin_email: str, linkedin_password: str):
        self.email = linkedin_email
        self.password = linkedin_password
        self.session_id: Optional[str] = None
        self.collected_profiles: List[ProfileData] = []
        self.client = anthropic.Anthropic(api_key=settings.ANTHROPIC_API_KEY)
        self.tools = [] # Initialize tools list if needed, though not used directly in these methods

    async def call_tool(self, mcp_session: ClientSession, tool_name: str, arguments: dict) -> dict:
        """Call MCP tool and parse JSON response"""
        try:
            result = await mcp_session.call_tool(tool_name, arguments=arguments)
            return json.loads(result.content[0].text)
        except Exception as e:
            LogCollector.add(f"âŒ Tool {tool_name} failed: {e}")
            return {"success": False, "error": str(e)}

    async def detect_gender(self, name: str, image_url: Optional[str]) -> str:
        """Detect gender from name and optional image URL using Claude"""
        try:
            user_content = [
                {"type": "text", "text": f"The person's name is '{name}'. Based on the image url (if provided) and the name, detect the gender. If there is no image url, use the name to detect the gender. Respond only: Male or Female."}
            ]
            
            if image_url:
                # Claude expects image data or a specific image block structure. 
                # Since we have a URL, we might need to fetch it if we were sending base64, 
                # but Claude 3.5 Sonnet supports image URLs in some contexts or we might need to just pass the URL as text if the model can browse (it can't here).
                # However, the user request specifically asked to use `self.client.messages.create`.
                # Standard Anthropic API for images usually requires base64. 
                # BUT, if the previous code was sending a URL to Azure, Azure might have been downloading it.
                # Let's check if we can just pass the URL in text for now, or if we should try to use the image block.
                # The user prompt example showed `messages=messages` and `tools=self.tools`.
                # For simplicity and robustness given I can't easily fetch/encode images here without more deps/async complexity in a sync client call (Anthropic client is sync by default unless AsyncAnthropic is used),
                # I will pass the image URL in the text and ask Claude to infer from it if possible (unlikely without vision) OR just rely on the name if the image can't be processed.
                # WAIT, the user said "Use always the Claude... response = self.client.messages.create(...)".
                # I will stick to the text prompt with the name, and mention the image URL in text. 
                # If I really need vision, I'd need to download and base64 encode. 
                # Let's try to be safe and just use the name for now if image handling is complex, 
                # OR better: The previous code sent `{"type": "image_url", "image_url": {"url": image_url}}`.
                # Anthropic API supports `{"type": "image", "source": {"type": "base64", "media_type": ..., "data": ...}}`. It does NOT support remote URLs directly in the API yet (usually).
                # Given I am using the standard `anthropic` library, I should probably just rely on the name to be safe, OR try to implement fetching.
                # But `detect_gender` is `async`. The `anthropic` client I initialized is SYNC (`anthropic.Anthropic`).
                # I should probably wrap the call or use `AsyncAnthropic`.
                # The user code snippet `response = self.client.messages.create` suggests sync usage.
                # But `detect_gender` is `async def`.
                # I'll use the sync client inside the async function (it will block the loop briefly, but acceptable for this scale).
                
                # RE-READING USER REQUEST: "Use always the Claude ... response = self.client.messages.create ... so delete Azure"
                # It doesn't explicitly say "support images via URL".
                # I will pass the image URL in the text description so if the model has any knowledge (unlikely) or just to keep the prompt similar.
                user_content[0]["text"] += f" Image URL: {image_url}"

            messages = [
                {"role": "user", "content": user_content}
            ]

            response = self.client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=4096,
                messages=messages
            )
            
            gender = response.content[0].text.strip().lower()

            if "male" in gender and "female" not in gender:
                return "Male"
            elif "female" in gender:
                return "Female"
            return "Unknown"

        except Exception as e:
            LogCollector.add(f"Gender detection failed: {e}")
            return "Unknown"

    async def estimate_age_from_education_llm(self, education_data: List[Dict[str, Any]]) -> Optional[int]:
        """Use Azure OpenAI LLM to analyze education data and estimate age"""
        if not education_data:
            return None

        try:
            current_year = datetime.now().year
            education_text = "\n".join([
                f"- School: {edu.get('school', 'N/A')}, Degree: {edu.get('degree', 'N/A')}, Date: {edu.get('date_range', 'N/A')}"
                for edu in education_data
            ])

            prompt = f"""You are an expert at estimating age based on educational history.

Current year: {current_year}

Education History:
{education_text}

Based on this education history, estimate the person's current age. Consider:
- High school/BaccalaurÃ©at typically ends at age 18
- Bachelor's degree typically ends at age 22
- Master's/MBA typically ends at age 24
- PhD typically ends at age 28
- Calculate from the most recent graduation date

Respond with ONLY a number representing the estimated age (e.g., 28). If you cannot estimate, respond with "Unknown"."""

            response = self.client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=4096,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )

            age_text = response.content[0].text.strip()

            try:
                age = int(age_text)
                if 18 <= age <= 80:
                    return age
                else:
                    return None
            except ValueError:
                return None

        except Exception as e:
            LogCollector.add(f"Age estimation via LLM failed: {e}")
            return None

    async def extract_education_for_profile(self, mcp_session: ClientSession, profile_url: str) -> Dict[str, Any]:
        try:
            result = await self.call_tool(
                mcp_session, "extract_education_data",
                {"session_id": self.session_id, "profile_url": profile_url}
            )
            return result
        except Exception as e:
            LogCollector.add(f"Failed to extract education for {profile_url}: {e}")
            return {"success": False, "education": []}

    async def extract_and_analyze_all_profiles(
        self,
        mcp_session: ClientSession,
        search_url: str,
        keywords: str,
        location_name: str,
        limit: int = 2,
        extract_education: bool = True
    ) -> List[ProfileData]:
        
        result = await self.call_tool(
            mcp_session, "extract_all_search_profiles_with_images",
            {"session_id": self.session_id, "search_url": search_url}
        )
        if not result.get("success"):
            LogCollector.add(f"âš ï¸ Failed to extract profiles: {result.get('message')}")
            return []

        raw_profiles = result.get("profiles", [])
        
        # === LIMIT TO REQUESTED NUMBER OF PROFILES ===
        if len(raw_profiles) > limit:
            LogCollector.add(f"âš ï¸ Limiting extraction to {limit} profiles (found {len(raw_profiles)}).")
            raw_profiles = raw_profiles[:limit]
            
        profiles = []

        for i, raw_profile in enumerate(raw_profiles, 1):
            LogCollector.add(f"Processing profile {i}/{len(raw_profiles)}: {raw_profile.get('name')}")

            profile = ProfileData(
                name=raw_profile.get("name"),
                url=raw_profile.get("url"),
                location=location_name,
                keyword=keywords,
                image_url=raw_profile.get("imageUrl"),
                search_rank=i,
                position=raw_profile.get("position")
            )

            LogCollector.add(f"   Detecting gender for {profile.name}...")
            profile.gender = await self.detect_gender(profile.name, profile.image_url)
            LogCollector.add(f"  âœ… Gender: {profile.gender}")

            if extract_education and profile.url:
                LogCollector.add(f"  ðŸŽ“ Extracting education data...")
                edu_result = await self.extract_education_for_profile(mcp_session, profile.url)

                if edu_result.get("success"):
                    education_list = edu_result.get("education", [])
                    profile.education = education_list
                    
                    if education_list:
                        LogCollector.add(f"  ðŸ“š Found {len(education_list)} education entries:")
                        for edu in education_list:
                            LogCollector.add(f"     - {edu.get('school')} | {edu.get('degree')} | {edu.get('date_range')}")

                        # Use LLM to estimate age
                        LogCollector.add(f"   Using LLM to estimate age...")
                        profile.estimated_age = await self.estimate_age_from_education_llm(education_list)

                        if profile.estimated_age:
                            LogCollector.add(f"   Estimated Age: {profile.estimated_age} years old")
                        else:
                            LogCollector.add(f"  âš ï¸ Could not estimate age")
                    else:
                        LogCollector.add(f"  âš ï¸ No education data found")
                else:
                    LogCollector.add(f"  âŒ Education extraction failed")
                
                await asyncio.sleep(2.0)

            profiles.append(profile)
            await asyncio.sleep(0.5)

        return profiles

    async def run(self, search_url: str, keywords: str, location_name: str, limit: int = 2, extract_education: bool = True) -> Dict[str, Any]:
        # Use the configured python environment to run the server script
        server_params = StdioServerParameters(command="python", args=[settings.MCP_SERVER_SCRIPT], env=None)
        try:
            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as mcp_session:
                    await mcp_session.initialize()

                    # Login
                    LogCollector.add("ðŸ” Logging into LinkedIn...")
                    login_result = await self.call_tool(mcp_session, "login_linkedin",
                                                       {"email": self.email, "password": self.password})
                    if not login_result.get("success"):
                        return {"success": False, "error": "Login failed", "profiles": []}

                    self.session_id = login_result.get("session_id")
                    LogCollector.add("âœ… Login successful")

                    LogCollector.add("ðŸ” Extracting profiles from search results...")
                    self.collected_profiles = await self.extract_and_analyze_all_profiles(
                        mcp_session, search_url, keywords, location_name, limit, extract_education
                    )

                    await self.call_tool(mcp_session, "close_browser", {"session_id": self.session_id})

                    complete_profiles = [p for p in self.collected_profiles if p.is_complete()]
                    LogCollector.add(f"âœ… Workflow complete. Processed {len(self.collected_profiles)} profiles.")
                    
                    return {
                        "success": True,
                        "total_profiles": len(self.collected_profiles),
                        "complete_profiles": len(complete_profiles),
                        "profiles": [p.to_dict() for p in complete_profiles],
                        "all_profiles": [p.to_dict() for p in self.collected_profiles]
                    }

        except Exception as e:
            LogCollector.add(f"âŒ Agent failed: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e), "profiles": [p.to_dict() for p in self.collected_profiles]}

async def run_linkedin_workflow(keyword: str, location: str, limit: int = 2) -> Dict[str, Any]:
    """Orchestrate the entire workflow"""
    location_id = LOCATION_IDS.get(location.lower(), "106186529") # Default to Casablanca
    search_url = build_linkedin_search_url(keyword, location_id)
    
    agent = LinkedInAutonomousAgent(settings.LINKEDIN_EMAIL, settings.LINKEDIN_PASSWORD)
    results = await agent.run(
        search_url=search_url,
        keywords=keyword,
        location_name=location,
        limit=limit,
        extract_education=True
    )
    
    
    # Save to JSON (Append mode)
    existing_data = {}
    if os.path.exists(settings.JSON_OUTPUT_FILE):
        try:
            with open(settings.JSON_OUTPUT_FILE, "r", encoding="utf-8") as f:
                existing_data = json.load(f)
        except Exception:
            existing_data = {}
            
    # Merge new profiles
    all_profiles_list = existing_data.get("all_profiles", [])
    if results.get("all_profiles"):
        all_profiles_list.extend(results["all_profiles"])
        
    final_data = {
        "success": True,
        "total_profiles": len(all_profiles_list),
        "all_profiles": all_profiles_list
    }

    with open(settings.JSON_OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(final_data, f, indent=2, ensure_ascii=False)
        
    LogCollector.add(f"ðŸ’¾ Saved results to {settings.JSON_OUTPUT_FILE}")
        
    # Save to Database
    if results.get("all_profiles"):
        db_service.save_profiles(results["all_profiles"])
        
    return results
